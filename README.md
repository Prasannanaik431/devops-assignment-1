# FastAPI DevOps Assignment

A complete DevOps implementation featuring Infrastructure as Code, CI/CD pipeline, Kubernetes deployment, monitoring, and auto-scaling.

## ğŸ“‹ Table of Contents

- [Architecture Overview](#architecture-overview)
- [Infrastructure Setup](#infrastructure-setup)
- [CI/CD Pipeline](#cicd-pipeline)
- [Deployment Environments](#deployment-environments)
- [Monitoring Strategy](#monitoring-strategy)
- [Scalability](#scalability)
- [Quick Start](#quick-start)

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ARCHITECTURE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   GitHub    â”‚â”€â”€â”€â”€â–¶â”‚  GitHub     â”‚â”€â”€â”€â”€â–¶â”‚     Docker Hub              â”‚   â”‚
â”‚  â”‚   (Code)    â”‚     â”‚  Actions    â”‚     â”‚  prasannasn/fastapi-devops  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                                                â”‚
â”‚                             â–¼                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Kubernetes Cluster (3 VMs)                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚ Control Plane   â”‚ â”‚  Worker Node 1  â”‚ â”‚  Worker Node 2  â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ (10.160.0.3)    â”‚ â”‚  (10.160.0.4)   â”‚ â”‚  (10.160.0.5)   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚                 â”‚ â”‚                 â”‚ â”‚                 â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ API Server    â”‚ â”‚ â€¢ FastAPI Pods  â”‚ â”‚ â€¢ FastAPI Pods  â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ etcd          â”‚ â”‚ â€¢ Flannel CNI   â”‚ â”‚ â€¢ Flannel CNI   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Scheduler     â”‚ â”‚ â€¢ kube-proxy    â”‚ â”‚ â€¢ kube-proxy    â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Controller    â”‚ â”‚                 â”‚ â”‚                 â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                                                                        â”‚  â”‚
â”‚  â”‚  Namespaces:                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚   dev    â”‚  â”‚  stage   â”‚  â”‚   prod   â”‚  â”‚  monitoring â”‚            â”‚  â”‚
â”‚  â”‚  â”‚ :30080   â”‚  â”‚ :30081   â”‚  â”‚ :30082   â”‚  â”‚   :30090    â”‚            â”‚  â”‚
â”‚  â”‚  â”‚ 2 replicasâ”‚  â”‚ 2 replicasâ”‚  â”‚ 3 replicasâ”‚  â”‚ Prometheus  â”‚            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Infrastructure Setup

### Prerequisites

- Google Cloud Platform account
- `gcloud` CLI configured
- SSH key pair for VM access
- OpenTofu/Terraform installed

### Infrastructure Components

| Component | Technology | Purpose |
|-----------|------------|---------|
| IaC | OpenTofu | Infrastructure provisioning |
| Container Runtime | containerd | Running containers |
| Kubernetes | kubeadm v1.30 | Container orchestration |
| CNI | Flannel | Pod networking |
| Load Balancer | NodePort Services | Traffic distribution |

### VM Configuration

| VM | Role | Internal IP | External IP | Resources |
|----|------|-------------|-------------|-----------|
| devops-instance-1 | Control Plane | 10.160.0.3 | 34.14.169.168 | 2 vCPU, 4GB RAM |
| devops-instance-2 | Worker Node | 10.160.0.4 | 34.100.156.67 | 2 vCPU, 4GB RAM |
| devops-instance-3 | Worker Node | 10.160.0.5 | 34.14.213.230 | 2 vCPU, 4GB RAM |

### OpenTofu Setup

```bash
cd opentofu/
tofu init
tofu plan
tofu apply
```

---

## ğŸš€ CI/CD Pipeline

### Pipeline Stages

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Quality â”‚â”€â”€â”€â–¶â”‚    Build     â”‚â”€â”€â”€â–¶â”‚   Security   â”‚â”€â”€â”€â–¶â”‚    Deploy    â”‚
â”‚              â”‚    â”‚              â”‚    â”‚    Scan      â”‚    â”‚              â”‚
â”‚ â€¢ flake8     â”‚    â”‚ â€¢ Docker     â”‚    â”‚ â€¢ Trivy      â”‚    â”‚ â€¢ kubectl    â”‚
â”‚ â€¢ black      â”‚    â”‚ â€¢ Push to    â”‚    â”‚ â€¢ CVE check  â”‚    â”‚ â€¢ Rollout    â”‚
â”‚ â€¢ isort      â”‚    â”‚   Docker Hub â”‚    â”‚              â”‚    â”‚ â€¢ Verify     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Branch to Environment Mapping

| Branch | Environment | Namespace | NodePort | Replicas |
|--------|-------------|-----------|----------|----------|
| `prasanna` | Development | dev | 30080 | 2 |
| `stage` | Staging | stage | 30081 | 2 |
| `main` | Production | prod | 30082 | 3 |

### GitHub Actions Workflow

Located at: `.github/workflows/ci-cd.yaml`

**Required Secrets:**
- `DOCKERHUB_USERNAME` - Docker Hub username
- `DOCKERHUB_TOKEN` - Docker Hub access token
- `SSH_PRIVATE_KEY` - SSH private key for cluster access
- `CONTROL_PLANE_IP` - Control plane external IP

### Triggering Deployments

```bash
# Automatic: Push to branch
git push origin prasanna  # Deploys to dev
git push origin stage     # Deploys to staging
git push origin main      # Deploys to production

# Manual: Workflow dispatch
# Go to Actions tab â†’ Run workflow â†’ Select environment
```

---

## ğŸŒ Deployment Environments

### Development (dev)

- **Purpose**: Feature testing, debugging
- **Replicas**: 2
- **Resources**: 64Mi-256Mi memory, 50m-500m CPU
- **Endpoint**: `http://<worker-ip>:30080`

### Staging (stage)

- **Purpose**: Pre-production testing, QA
- **Replicas**: 2
- **Resources**: 128Mi-256Mi memory, 100m-500m CPU
- **Endpoint**: `http://<worker-ip>:30081`

### Production (prod)

- **Purpose**: Live traffic, end users
- **Replicas**: 3 (auto-scales 2-10)
- **Resources**: 128Mi-512Mi memory, 100m-1000m CPU
- **Endpoint**: `http://<worker-ip>:30082`
- **Features**: HPA enabled, Prometheus monitoring

---

## ğŸ“Š Monitoring Strategy

### Prometheus Setup

- **Namespace**: monitoring
- **NodePort**: 30090
- **Scrape Interval**: 15s

### Metrics Collected

| Metric Type | Source | Purpose |
|-------------|--------|---------|
| Application | FastAPI pods | Request latency, error rates |
| Container | cAdvisor | CPU, memory, network |
| Kubernetes | kube-state-metrics | Pod, deployment health |

### Accessing Prometheus

```bash
# Via NodePort (if firewall allows)
http://<worker-ip>:30090

# Via kubectl port-forward
kubectl port-forward -n monitoring svc/prometheus 9090:9090
# Then access: http://localhost:9090
```

### Alerting (Future Enhancement)

Configure AlertManager for:
- High CPU/Memory usage (>80%)
- Pod restart counts
- Response time degradation
- Service availability

---

## ğŸ“ˆ Scalability

### Horizontal Pod Autoscaler (HPA)

Production environment has HPA configured:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: fastapi-hpa
  namespace: prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: fastapi
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
```

### Scaling Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           SCALING DIAGRAM               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Traffic Increase                              Traffic Decrease
         â”‚                                              â”‚
         â–¼                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HPA Monitors   â”‚                          â”‚  HPA Monitors   â”‚
â”‚  CPU/Memory     â”‚                          â”‚  CPU/Memory     â”‚
â”‚  Metrics        â”‚                          â”‚  Metrics        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                            â”‚
         â–¼                                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CPU > 70% or    â”‚                          â”‚ CPU < 50% and   â”‚
â”‚ Memory > 80%    â”‚                          â”‚ Memory < 60%    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                            â”‚
         â–¼                                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scale UP       â”‚                          â”‚  Scale DOWN     â”‚
â”‚  (max: 10 pods) â”‚                          â”‚  (min: 2 pods)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Current: 3 pods â”€â”€â”€â”€â”€â”€â–¶ High Load: 10 pods â”€â”€â”€â”€â”€â”€â–¶ Low Load: 2 pods
```

### Manual Scaling

```bash
# Scale deployment manually
kubectl scale deployment/fastapi -n prod --replicas=5

# Check HPA status
kubectl get hpa -n prod

# Watch scaling in action
kubectl get pods -n prod -w
```

### Vertical Scaling (Node Level)

To add more worker nodes:

1. Provision new VM with same specs
2. Install kubeadm, kubelet, containerd
3. Join cluster: `kubeadm join <control-plane>:6443 --token <token>`

---

## ğŸš€ Quick Start

### 1. Run Application Locally

```bash
# Install dependencies
pip install -r requirements.txt

# Run server
make run-server
# OR
uvicorn app.main:app --host 0.0.0.0 --port 8000

# Access: http://localhost:8000
```

### 2. Build Docker Image

```bash
docker build -t prasannasn/fastapi-devops:latest .
docker push prasannasn/fastapi-devops:latest
```

### 3. Deploy to Kubernetes

```bash
# Using kubectl
kubectl apply -f k8s/overlays/dev/

# Or trigger CI/CD
git push origin prasanna
```

### 4. Verify Deployment

```bash
# Check pods
kubectl get pods -A | grep fastapi

# Test endpoints
curl http://<worker-ip>:30080  # dev
curl http://<worker-ip>:30081  # stage
curl http://<worker-ip>:30082  # prod
```

---

## ğŸ“ Project Structure

```
devops-assignment/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py              # FastAPI application
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ base/                # Base Kubernetes manifests
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â””â”€â”€ kustomization.yaml
â”‚   â”œâ”€â”€ overlays/            # Environment-specific configs
â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ stage/
â”‚   â”‚   â””â”€â”€ prod/
â”‚   â””â”€â”€ monitoring/          # Prometheus configs
â”œâ”€â”€ opentofu/                # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â””â”€â”€ provider.tf
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yaml       # GitHub Actions pipeline
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

---

## ğŸ”’ Security

- Docker images scanned with Trivy
- Non-root container execution
- Resource limits on all pods
- RBAC for Prometheus
- SSH-based deployment (no exposed K8s API)

---

## ğŸ“ License

This project is for educational purposes as part of a DevOps assignment.

---

## ğŸ‘¤ Author

Prasanna Naik
